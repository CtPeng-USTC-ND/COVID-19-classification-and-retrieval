{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "understood-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from skimage import transform\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from triplet_loss import *\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import scipy\n",
    "import pandas as pd\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "peripheral-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy\n",
    "NCP_masks = glob.glob('/data2/Cpeng/NCP_lung_masks/*')\n",
    "mask = cv2.imread(NCP_masks[5],0)\n",
    "mask[mask>0]=1\n",
    "print(mask.min())\n",
    "print(mask.max())\n",
    "print(mask.shape)\n",
    "plt.imshow(mask)\n",
    "mt = scipy.ndimage.distance_transform_edt(mask)\n",
    "plt.figure()\n",
    "plt.imshow(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "convenient-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "NCP_images = glob.glob('/data2/Cpeng/NCP_raw_images/*')\n",
    "CP_images = glob.glob('/data2/Cpeng/CP_raw_images/*')\n",
    "Normal_images = glob.glob('/data2/Cpeng/Normal_raw_images/*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "reverse-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lesion_slices = pd.read_csv('/data2/Cpeng/COVID/lesions_slices.csv')\n",
    "# Normal_slices = pd.read_csv('/data2/Cpeng/COVID/Normal_slices.csv')\n",
    "# print(len(lesion_slices))\n",
    "# # print(len(Normal_slices))\n",
    "# NCP_slices = lesion_slices['imgpath'].tolist()[36894:58766]\n",
    "# CP_slices = lesion_slices['imgpath'].tolist()[0:36894]\n",
    "# N_slices = Normal_slices['imgpath'].tolist()\n",
    "# print(len(NCP_slices))\n",
    "# print(len(CP_slices))\n",
    "# print(len(N_slices))\n",
    "# print(N_slices[0])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "NCP_train, NCP_val, _, _ = train_test_split(NCP_images, NCP_images, test_size=0.3, random_state=42)\n",
    "CP_train, CP_val, _, _ = train_test_split(CP_images, CP_images, test_size=0.3, random_state=42)\n",
    "Normal_train, Normal_val, _, _ = train_test_split(Normal_images, Normal_images, test_size=0.2, random_state=42)\n",
    "# print(len(NCP_train))\n",
    "# print(len(CP_train))\n",
    "# print(len(Normal_train))\n",
    "CP_Normal_train = []\n",
    "CP_Normal_train.extend(CP_train)\n",
    "CP_Normal_train.extend(Normal_train)                                        \n",
    "CP_Normal_val = []\n",
    "CP_Normal_val.extend(CP_val[:])\n",
    "CP_Normal_val.extend(Normal_val[:])\n",
    "# print(len(CP_Normal_train))\n",
    "# print(len(CP_Normal_val))\n",
    "# print(CP_Normal_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prime-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal = glob.glob('/data2/Cpeng/COVID/Normal/*/*/*')\n",
    "# print(Normal[0])\n",
    "# Normal_df = pd.DataFrame({'imgpath':Normal})\n",
    "# Normal_df.to_csv('/data2/Cpeng/COVID/Normal_slices.csv',index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "inner-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import fliplr\n",
    "class COVID_19(Dataset):\n",
    "    def __init__(self, file_path_NCP, file_path_CP_Normal, phase='train'):\n",
    "        self.path_list_NCP = file_path_NCP\n",
    "        self.path_list_CP_Normal = file_path_CP_Normal\n",
    "        self.phase = phase\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        num_NCP = len(self.path_list_NCP)\n",
    "        num_CP_Normal = len(self.path_list_CP_Normal)\n",
    "        \n",
    "        image_anchor_NCP,mask_anchor_NCP= self.load_data(self.path_list_NCP[index])\n",
    "        randn_aug_0=np.random.randint(0,3)\n",
    "        if randn_aug_0==0:\n",
    "            image_anchor_NCP = fliplr(image_anchor_NCP)\n",
    "            mask_anchor_NCP = fliplr(mask_anchor_NCP)\n",
    "        if randn_aug_0==1:\n",
    "            image_anchor_NCP = transform.rotate(image_anchor_NCP,2)\n",
    "            mask_anchor_NCP = transform.rotate(mask_anchor_NCP,2)\n",
    "        if randn_aug_0==2:\n",
    "            image_anchor_NCP = transform.rotate(image_anchor_NCP,-2)\n",
    "            mask_anchor_NCP = transform.rotate(mask_anchor_NCP,-2)\n",
    "        image_anchor_NCP,mask_anchor_NCP = self.normalize_data(image_anchor_NCP,mask_anchor_NCP)\n",
    "        anchor_map = scipy.ndimage.distance_transform_edt(mask_anchor_NCP)\n",
    "        if anchor_map.max()>0:\n",
    "            anchor_map = anchor_map/anchor_map.max()\n",
    "        ########## For Classification\n",
    "        ### positive\n",
    "        randn = np.random.randint(0,num_NCP)\n",
    "        image_positive_NCP_D,mask_positive_NCP_D= self.load_data(self.path_list_NCP[randn])\n",
    "        randn_aug_1=np.random.randint(0,3)\n",
    "        if randn_aug_1==0:\n",
    "            image_positive_NCP_D = fliplr(image_positive_NCP_D)\n",
    "            mask_positive_NCP_D = fliplr(mask_positive_NCP_D)\n",
    "        if randn_aug_1==1:\n",
    "            image_positive_NCP_D = transform.rotate(image_positive_NCP_D,2)\n",
    "            mask_positive_NCP_D = transform.rotate(mask_positive_NCP_D,2)\n",
    "        if randn_aug_1==2:\n",
    "            image_positive_NCP_D = transform.rotate(image_positive_NCP_D,-2)\n",
    "            mask_positive_NCP_D = transform.rotate(mask_positive_NCP_D,-2)\n",
    "        image_positive_NCP_D,mask_positive_NCP_D = self.normalize_data(image_positive_NCP_D,mask_positive_NCP_D)\n",
    "        positive_map_D = scipy.ndimage.distance_transform_edt(mask_positive_NCP_D)\n",
    "        if positive_map_D.max()>0:\n",
    "            positive_map_D = positive_map_D/positive_map_D.max()\n",
    "        ###### negative\n",
    "        randn_1 = np.random.randint(0,num_CP_Normal)\n",
    "        image_negative_NCP_D,mask_negative_NCP_D= self.load_data(self.path_list_CP_Normal[randn_1])\n",
    "        image_negative_NCP_D,mask_negative_NCP_D= self.normalize_data(image_negative_NCP_D,mask_negative_NCP_D)\n",
    "        negative_map_D = scipy.ndimage.distance_transform_edt(mask_negative_NCP_D)\n",
    "        if negative_map_D.max()>0:\n",
    "            negative_map_D = negative_map_D/negative_map_D.max()\n",
    "        \n",
    "        \n",
    "        ########## For similar case recommendation\n",
    "        #### positive\n",
    "        randn_aug_2 = np.random.randint(0,4)\n",
    "        if randn_aug_2==0:\n",
    "            image_positive_NCP_R = fliplr(image_anchor_NCP)\n",
    "            mask_positive_NCP_R = fliplr(mask_anchor_NCP)\n",
    "        elif randn_aug_0==1:\n",
    "            image_positive_NCP_R = transform.rotate(image_anchor_NCP,2)\n",
    "            mask_positive_NCP_R = transform.rotate(mask_anchor_NCP,2)\n",
    "        else:\n",
    "            image_positive_NCP_R = transform.rotate(image_anchor_NCP,-2)\n",
    "            mask_positive_NCP_R = transform.rotate(mask_anchor_NCP,-2)\n",
    "        image_positive_NCP_R,mask_positive_NCP_R = self.normalize_data(image_positive_NCP_R,mask_positive_NCP_R)\n",
    "        positive_map_R = scipy.ndimage.distance_transform_edt(mask_positive_NCP_R)\n",
    "        if positive_map_R.max()>0:\n",
    "            positive_map_R = positive_map_R/positive_map_R.max()\n",
    "        \n",
    "        ###### negative\n",
    "        image_negative_NCP_R=np.zeros(256)\n",
    "        mask_negative_NCP_R=np.zeros(256)\n",
    "        original_patient = self.path_list_NCP[index].split('/')[-1].split('_')[1]\n",
    "        for i in range(1000):\n",
    "            randn_2 = np.random.randint(0,num_NCP)\n",
    "            new_patient = self.path_list_NCP[randn_2].split('/')[-1].split('_')[1]\n",
    "            if original_patient == new_patient:\n",
    "                continue\n",
    "            else:\n",
    "                image_negative_NCP_R,mask_negative_NCP_R = self.load_data(self.path_list_NCP[randn_2])\n",
    "                break\n",
    "        randn_aug_3 = np.random.randint(0,4)\n",
    "        if randn_aug_3==0:\n",
    "            image_negative_NCP_R = fliplr(image_negative_NCP_R)\n",
    "            mask_negative_NCP_R = fliplr(mask_negative_NCP_R)\n",
    "        if randn_aug_3==1:\n",
    "            image_negative_NCP_R = transform.rotate(image_negative_NCP_R,2)\n",
    "            mask_negative_NCP_R = transform.rotate(mask_negative_NCP_R,2)\n",
    "        if randn_aug_3==2:\n",
    "            image_negative_NCP_R = transform.rotate(image_negative_NCP_R,-2)\n",
    "            mask_negative_NCP_R = transform.rotate(mask_negative_NCP_R,-2)\n",
    "        image_negative_NCP_R,mask_negative_NCP_R = self.normalize_data(image_negative_NCP_R,mask_negative_NCP_R)\n",
    "        negative_map_R = scipy.ndimage.distance_transform_edt(mask_negative_NCP_R)\n",
    "        if negative_map_R.max()>0:\n",
    "            negative_map_R = negative_map_R/negative_map_R.max()\n",
    "        label_anchor = 0\n",
    "        label_positive = 0\n",
    "        label_negative = 1\n",
    "        return self.process_data(image_anchor_NCP,mask_anchor_NCP,anchor_map, \\\n",
    "                image_positive_NCP_D,mask_positive_NCP_D,positive_map_D,  image_negative_NCP_D,mask_negative_NCP_D,negative_map_D, \\\n",
    "                image_positive_NCP_R,mask_positive_NCP_R,positive_map_R,  image_negative_NCP_R,mask_negative_NCP_R,negative_map_R, \\\n",
    "                                label_anchor,label_positive,label_negative)\n",
    "        \n",
    "    def load_data(self, file_path):\n",
    "        image = cv2.imread(file_path,0)\n",
    "        image_type = file_path.split('/')[-2].split('_')[0]\n",
    "        if image_type == 'NCP':\n",
    "            mask_path = os.path.join('/data2/Cpeng/NCP_lung_masks/',file_path.split('/')[-1])\n",
    "        elif image_type == 'CP':\n",
    "            mask_path = os.path.join('/data2/Cpeng/CP_lung_masks/',file_path.split('/')[-1])\n",
    "        else:\n",
    "            mask_path = os.path.join('/data2/Cpeng/Normal_lung_masks/',file_path.split('/')[-1])\n",
    "        mask = cv2.imread(mask_path,0)\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    \n",
    "    def normalize_data(self,image,mask):\n",
    "        image = cv2.resize(image,(224,224), interpolation=cv2.INTER_CUBIC)\n",
    "        image = image-image.min()\n",
    "        image = (image/image.max()).astype(np.float32)\n",
    "        mask = cv2.resize(mask,(224,224), interpolation=cv2.INTER_CUBIC)\n",
    "        mask[mask>0]=1.\n",
    "        return image, mask\n",
    "        \n",
    "    def process_data(self, *args):\n",
    "        a1,a2,a3,a4,a5,a6,a7,a8,a9,a10,a11,a12,a13,a14,a15 = [item[np.newaxis, ...].astype(np.float32) for item in args[0:15]]\n",
    "        a16,a17,a18 = [item for item in args[15:18]]\n",
    "        return a1,a2,a3,a4,a5,a6,a7,a8,a9,a10,a11,a12,a13,a14,a15,a16,a17,a18\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.path_list_NCP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afraid-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from config import *\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features,128)\n",
    "coarse_network = nn.Sequential(*list(model.children())[0:5])\n",
    "fine_network = nn.Sequential(*list(model.children())[5:9])\n",
    "class COVID_CR_network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(COVID_CR_network,self).__init__()\n",
    "        self.main_network = nn.Sequential(*list(model.children())[0:5])\n",
    "        self.Detection_network = nn.Sequential(*list(model.children())[5:9])\n",
    "        self.Recommendation_network = nn.Sequential(*list(model.children())[5:9])\n",
    "        self.fc1 = nn.Linear(512,128)\n",
    "        self.fc2 = nn.Linear(512,128)\n",
    "        self.fc3 = nn.Linear(128, 2)\n",
    "#     def l2_norm(self,input):\n",
    "#         input_size = input.size()\n",
    "#         buffer = torch.pow(input, 2)\n",
    "\n",
    "#         normp = torch.sum(buffer, 1).add_(1e-10)\n",
    "#         norm = torch.sqrt(normp)\n",
    "\n",
    "#         _output = torch.div(input, norm.view(-1, 1).expand_as(input))\n",
    "\n",
    "#         output = _output.view(input_size)\n",
    "\n",
    "#         return output\n",
    "    def forward(self,image_anchor,mask_anchor,map_anchor,\n",
    "                image_positive_D,mask_positive_D,map_positive_D,image_negative_D,mask_negative_D,map_negative_D,\n",
    "                image_positive_R,mask_positive_R,map_positive_R,image_negative_R,mask_negative_R,map_negative_R):\n",
    "        \n",
    "        input_anchor = torch.cat([image_anchor,image_anchor*mask_anchor,map_anchor],dim=1)\n",
    "        \n",
    "        input_positive_D = torch.cat([image_positive_D,image_positive_D*mask_positive_D,map_positive_D],dim=1)\n",
    "        input_negative_D = torch.cat([image_negative_D,image_negative_D*mask_negative_D,map_negative_D],dim=1)\n",
    "        output_anchor_D = self.Detection_network(self.main_network(input_anchor))\n",
    "        output_positive_D = self.Detection_network(self.main_network(input_positive_D))\n",
    "        output_negative_D = self.Detection_network(self.main_network(input_negative_D))\n",
    "        \n",
    "        output_anchor_D = output_anchor_D.view(output_anchor_D.size(0), -1)\n",
    "        output_positive_D = output_positive_D.view(output_positive_D.size(0), -1)\n",
    "        output_negative_D = output_negative_D.view(output_negative_D.size(0), -1)\n",
    "        output_anchor_D = self.fc1(output_anchor_D)\n",
    "        output_positive_D = self.fc1(output_positive_D)\n",
    "        output_negative_D = self.fc1(output_negative_D)\n",
    "        \n",
    "        \n",
    "        input_positive_R = torch.cat([image_positive_R,image_positive_R*mask_positive_R,map_positive_R],dim=1)\n",
    "        input_negative_R = torch.cat([image_negative_R,image_negative_R*mask_negative_R,map_negative_R],dim=1)\n",
    "        output_anchor_R = self.Recommendation_network(self.main_network(input_anchor))\n",
    "        output_positive_R = self.Recommendation_network(self.main_network(input_positive_R))\n",
    "        output_negative_R = self.Recommendation_network(self.main_network(input_negative_R))\n",
    "        \n",
    "        \n",
    "        output_anchor_R = output_anchor_R.view(output_anchor_R.size(0), -1)\n",
    "        output_positive_R = output_positive_R.view(output_positive_R.size(0), -1)\n",
    "        output_negative_R = output_negative_R.view(output_negative_R.size(0), -1)\n",
    "        \n",
    "        output_anchor_R = self.fc2(output_anchor_R)\n",
    "        output_positive_R = self.fc2(output_positive_R)\n",
    "        output_negative_R = self.fc2(output_negative_R)\n",
    "        \n",
    "        return output_anchor_D,output_positive_D,output_negative_D,output_anchor_R,output_positive_R,output_negative_R\n",
    "    def classification(self,input_features):\n",
    "        output = self.fc3(input_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fancy-salem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): COVID_CR_network(\n",
      "    (main_network): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (4): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (Detection_network): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    )\n",
      "    (Recommendation_network): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    )\n",
      "    (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device_ids = [0,1,2,3]\n",
    "COVID_DR_model = COVID_CR_network()\n",
    "# checkpoint = torch.load('/data2/Cpeng/model_COVID_DR/checkpoint_120.pth.tar', map_location=\"cuda:0\")\n",
    "# COVID_DR_model.load_state_dict(checkpoint['state_dict'])\n",
    "COVID_DR_model.cuda(device=device_ids[0])\n",
    "COVID_DR_model = nn.DataParallel(COVID_DR_model,device_ids = device_ids)\n",
    "print(COVID_DR_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "impressive-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device('cpu' if not torch.cuda.is_available() else 'cuda')\n",
    "batch_size = 64*4\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "interim-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = COVID_19(NCP_train,CP_Normal_train, phase='train')\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "valset = COVID_19(NCP_val,CP_Normal_val, phase='train')\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "interesting-asian",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import *\n",
    "criterion_1 = nn.TripletMarginLoss(margin=1.2).cuda()\n",
    "criterion_2 = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adam(COVID_DR_model.parameters(), lr=1e-3,weight_decay=1e-5)\n",
    "optimizer = nn.DataParallel(optimizer, device_ids=device_ids)\n",
    "scheduler = StepLR(optimizer.module, 20, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "valued-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, checkpoint='checkpoint', snapshot=1):\n",
    "    if not os.path.exists(checkpoint): os.makedirs(checkpoint)\n",
    "    if snapshot and state['epoch'] % snapshot == 0:\n",
    "        torch.save(state, os.path.join(checkpoint, 'checkpoint_{}.pth.tar'.format(state['epoch'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "peaceful-puppy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "step=0\n",
    "epoches=401\n",
    "margin =1.2\n",
    "############\n",
    "l2_dist = PairwiseDistance(2)\n",
    "def l2_norm(input):\n",
    "        input_size = input.size()\n",
    "        buffer = torch.pow(input, 2)\n",
    "        \n",
    "        normp = torch.sum(buffer, 1).add_(1e-10)\n",
    "        norm = torch.sqrt(normp)\n",
    "        \n",
    "        _output = torch.div(input, norm.view(-1, 1).expand_as(input))\n",
    "        \n",
    "        output = _output.view(input_size)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "loss_train=0.0\n",
    "loss_val=0.0\n",
    "triplet_loss_train_D = 0.0\n",
    "triplet_loss_train_R = 0.0\n",
    "triplet_loss_val_D = 0.0\n",
    "triplet_loss_val_R = 0.0\n",
    "CE_loss_train_D = 0.0\n",
    "CE_loss_val_D = 0.0\n",
    "output_anchor_D = torch.linspace(-1,1,128)\n",
    "output_positive_D = torch.linspace(-1,1,128)\n",
    "output_negative_D = torch.linspace(-1,1,128)\n",
    "output_anchor_R = torch.linspace(-1,1,128)\n",
    "output_positive_R = torch.linspace(-1,1,128)\n",
    "output_negative_R = torch.linspace(-1,1,128)\n",
    "for epoch in range(1,epoches):\n",
    "    print('epoch:' + str(epoch))\n",
    "    \n",
    "    COVID_DR_model.train()\n",
    "    for i,data in enumerate(train_loader):\n",
    "        image_anchor,mask_anchor,map_anchor,image_positive_D,mask_positive_D,map_positive_D,image_negative_D,mask_negative_D,map_negative_D, \\\n",
    "                image_positive_R,mask_positive_R,map_positive_R,image_negative_R,mask_negative_R,map_negative_R, \\\n",
    "                                label_anchor,label_positive,label_negative = [item.to(device) for item in data]\n",
    "        \n",
    "        output_anchor_D,output_positive_D,output_negative_D,output_anchor_R,output_positive_R,output_negative_R = \\\n",
    "                        COVID_DR_model(image_anchor,mask_anchor,map_anchor,\n",
    "                                       image_positive_D,mask_positive_D,map_positive_D,image_negative_D,mask_negative_D,map_negative_D,\n",
    "                                       image_positive_R,mask_positive_R,map_positive_R,image_negative_R,mask_negative_R,map_negative_R)\n",
    "        \n",
    "        \n",
    "        output_anchor_D = l2_norm(output_anchor_D)\n",
    "        output_positive_D = l2_norm(output_positive_D)\n",
    "        output_negative_D = l2_norm(output_negative_D)\n",
    "        output_anchor_R = l2_norm(output_anchor_R)\n",
    "        output_positive_R = l2_norm(output_positive_R)\n",
    "        output_negative_R = l2_norm(output_negative_R)\n",
    "        \n",
    "        # Choose the hard negatives\n",
    "#         d_p_D = l2_dist.forward(output_anchor_D, output_positive_D)\n",
    "#         d_n_D = l2_dist.forward(output_anchor_D, output_negative_D)\n",
    "#         all_D = (d_n_D - d_p_D < margin).cpu().data.numpy().flatten()\n",
    "#         hard_triplets_D = np.where(all_D == 1)\n",
    "#         if len(hard_triplets_D[0]) == 0:\n",
    "#             continue\n",
    "#         out_selected_a_D = torch.from_numpy(output_anchor_D.cpu().data.numpy()[hard_triplets_D]).cuda()\n",
    "#         out_selected_p_D = torch.from_numpy(output_positive_D.cpu().data.numpy()[hard_triplets_D]).cuda()\n",
    "#         out_selected_n_D = torch.from_numpy(output_negative_D.cpu().data.numpy()[hard_triplets_D]).cuda()\n",
    "        # select data\n",
    "#         selected_image_a_D = torch.from_numpy(image_anchor.cpu().data.numpy()[hard_triplets_D]).cuda()\n",
    "#         selected_image_p_D = torch.from_numpy(image_positive_D.cpu().data.numpy()[hard_triplets_D]).cuda()\n",
    "#         selected_image_n_D = torch.from_numpy(image_negative_D.cpu().data.numpy()[hard_triplets_D]).cuda()\n",
    "        \n",
    "#         selected_mask_a_D = torch.from_numpy(mask_anchor.cpu().data.numpy()[hard_triplets_D]).cuda()\n",
    "#         selected_mask_p_D = torch.from_numpy(mask_positive_D.cpu().data.numpy()[hard_triplets_D]).cuda()\n",
    "#         selected_mask_n_D = torch.from_numpy(mask_negative_D.cpu().data.numpy()[hard_triplets_D]).cuda()\n",
    "        \n",
    "#         selected_map_a_D = torch.from_numpy(map_anchor.cpu().data.numpy()[hard_triplets_D]).cuda()\n",
    "#         selected_map_p_D = torch.from_numpy(map_positive_D.cpu().data.numpy()[hard_triplets_D]).cuda()\n",
    "#         selected_map_n_D = torch.from_numpy(map_negative_D.cpu().data.numpy()[hard_triplets_D]).cuda()\n",
    "        \n",
    "#         selected_label_p = torch.from_numpy(label_positive.cpu().numpy()[hard_triplets_D])\n",
    "#         selected_label_n= torch.from_numpy(label_negative.cpu().numpy()[hard_triplets_D])\n",
    "#         print(selected_image_a_D.size())\n",
    "#         print(selected_image_a_D.max())\n",
    "        ### classification\n",
    "#         print(selected_image_a_D.size())\n",
    "#         print(selected_image_p_D.size())\n",
    "#         output_anchor_D_1,output_positive_D_1,output_negative_D_1 = COVID_DR_model(\n",
    "#                     selected_image_a_D,selected_mask_a_D,selected_map_a_D,\n",
    "#                     selected_image_p_D,selected_mask_p_D,selected_map_p_D,selected_image_n_D,selected_mask_n_D,selected_map_n_D,\n",
    "#                     image_positive_R,mask_positive_R,map_positive_R,image_negative_R,mask_negative_R,map_negative_R)\n",
    "        \n",
    "        #compute loss\n",
    "#         triplet_loss_train_D = criterion_1(out_selected_a_D, out_selected_p_D, out_selected_n_D)\n",
    "        triplet_loss_train_D = criterion_1(output_anchor_D,output_positive_D,output_negative_D)\n",
    "        \n",
    "        \n",
    "#         predicted_labels = torch.cat([output_anchor_D_1,output_positive_D_1,output_negative_D_1])\n",
    "#         true_labels = torch.cat([selected_label_p.cuda(),selected_label_p.cuda(),selected_label_n.cuda()])\n",
    "#         print(output_anchor_D_1.size())\n",
    "#         print(label_anchor.size())\n",
    "        output_anchor_D_1 = COVID_DR_model.module.classification(output_anchor_D)\n",
    "        output_positive_D_1 = COVID_DR_model.module.classification(output_positive_D)\n",
    "        output_negative_D_1 = COVID_DR_model.module.classification(output_negative_D)\n",
    "        CE_loss_train_D = criterion_2(output_anchor_D_1,label_anchor)+ \\\n",
    "                        criterion_2(output_positive_D_1,label_positive)+ \\\n",
    "                        criterion_2(output_negative_D_1,label_negative)\n",
    "#         CE_loss_val_D = criterion_2(output_anchor_D_1.view(-1, 1),label_anchor.view(-1, 1))+ \\\n",
    "#                             criterion_2(output_positive_D_1.view(-1, 1),label_positive.view(-1, 1))+ \\\n",
    "#                             criterion_2(output_negative_D_1.view(-1, 1),label_negative.view(-1, 1))\n",
    "        ############ for Retrival\n",
    "        # Choose the hard negatives\n",
    "#         d_p_R = l2_dist.forward(output_anchor_R, output_positive_R)\n",
    "#         d_n_R = l2_dist.forward(output_anchor_R, output_negative_R)\n",
    "#         all_R = (d_n_R - d_p_R < margin).cpu().data.numpy().flatten()\n",
    "#         hard_triplets_R = np.where(all_R == 1)\n",
    "#         if len(hard_triplets_R[0]) == 0:\n",
    "#             continue\n",
    "#         out_selected_a_R = Variable(torch.from_numpy(output_anchor_R.cpu().data.numpy()[hard_triplets_R]).cuda())\n",
    "#         out_selected_p_R = Variable(torch.from_numpy(output_positive_R.cpu().data.numpy()[hard_triplets_R]).cuda())\n",
    "#         out_selected_n_R = Variable(torch.from_numpy(output_negative_R.cpu().data.numpy()[hard_triplets_R]).cuda())\n",
    "        #compute loss\n",
    "        triplet_loss_train_R = criterion_1(output_anchor_R,output_positive_R,output_negative_R)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         loss_train_D=triplet_loss_train_D + CE_loss_train_D\n",
    "#         loss_train_D=triplet_loss_train_D\n",
    "#         loss_train_R=triplet_loss_train_R\n",
    "        loss_train = 0.3*(0.4*triplet_loss_train_D+0.6*CE_loss_train_D)+0.7*triplet_loss_train_R\n",
    "        optimizer.module.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.module.step()\n",
    "    with torch.no_grad():\n",
    "        COVID_DR_model.eval()\n",
    "        for i,data in enumerate(val_loader):\n",
    "            image_anchor,mask_anchor,map_anchor,image_positive_D,mask_positive_D,map_positive_D,image_negative_D,mask_negative_D,map_negative_D, \\\n",
    "                image_positive_R,mask_positive_R,map_positive_R,image_negative_R,mask_negative_R,map_negative_R, \\\n",
    "                                label_anchor,label_positive,label_negative = [item.to(device) for item in data]\n",
    "            output_anchor_D,output_positive_D,output_negative_D,output_anchor_R,output_positive_R,output_negative_R = \\\n",
    "                        COVID_DR_model(image_anchor,mask_anchor,map_anchor,\n",
    "                                       image_positive_D,mask_positive_D,map_positive_D,image_negative_D,mask_negative_D,map_negative_D,\n",
    "                                       image_positive_R,mask_positive_R,map_positive_R,image_negative_R,mask_negative_R,map_negative_R)\n",
    "            \n",
    "            output_anchor_D = l2_norm(output_anchor_D)\n",
    "            output_positive_D = l2_norm(output_positive_D)\n",
    "            output_negative_D = l2_norm(output_negative_D)\n",
    "            output_anchor_R = l2_norm(output_anchor_R)\n",
    "            output_positive_R = l2_norm(output_positive_R)\n",
    "            output_negative_R = l2_norm(output_negative_R)\n",
    "            \n",
    "            # Choose the hard negatives\n",
    "#             d_p_D = l2_dist.forward(output_anchor_D, output_positive_D)\n",
    "#             d_n_D = l2_dist.forward(output_anchor_D, output_negative_D)\n",
    "#             all_D = (d_n_D - d_p_D < margin).cpu().data.numpy().flatten()\n",
    "#             hard_triplets_D = np.where(all_D == 1)\n",
    "#             if len(hard_triplets_D[0]) == 0:\n",
    "#                 continue\n",
    "#             out_selected_a_D = Variable(torch.from_numpy(output_anchor_D.cpu().data.numpy()[hard_triplets_D]).cuda())\n",
    "#             out_selected_p_D = Variable(torch.from_numpy(output_positive_D.cpu().data.numpy()[hard_triplets_D]).cuda())\n",
    "#             out_selected_n_D = Variable(torch.from_numpy(output_negative_D.cpu().data.numpy()[hard_triplets_D]).cuda())\n",
    "            # select data\n",
    "#             selected_image_a_D = Variable(torch.from_numpy(image_anchor.cpu().data.numpy()[hard_triplets_D]).cuda())\n",
    "#             selected_image_p_D = Variable(torch.from_numpy(image_positive_D.cpu().data.numpy()[hard_triplets_D]).cuda())\n",
    "#             selected_image_n_D = Variable(torch.from_numpy(image_negative_D.cpu().data.numpy()[hard_triplets_D]).cuda())\n",
    "\n",
    "#             selected_mask_a_D = Variable(torch.from_numpy(mask_anchor.cpu().data.numpy()[hard_triplets_D]).cuda())\n",
    "#             selected_mask_p_D = Variable(torch.from_numpy(mask_positive_D.cpu().data.numpy()[hard_triplets_D]).cuda())\n",
    "#             selected_mask_n_D = Variable(torch.from_numpy(mask_negative_D.cpu().data.numpy()[hard_triplets_D]).cuda())\n",
    "\n",
    "#             selected_map_a_D = Variable(torch.from_numpy(map_anchor.cpu().data.numpy()[hard_triplets_D]).cuda())\n",
    "#             selected_map_p_D = Variable(torch.from_numpy(map_positive_D.cpu().data.numpy()[hard_triplets_D]).cuda())\n",
    "#             selected_map_n_D = Variable(torch.from_numpy(map_negative_D.cpu().data.numpy()[hard_triplets_D]).cuda())\n",
    "\n",
    "#             selected_label_p = torch.from_numpy(label_positive.cpu().numpy()[hard_triplets_D])\n",
    "#             selected_label_n= torch.from_numpy(label_negative.cpu().numpy()[hard_triplets_D])\n",
    "\n",
    "#             ### classification\n",
    "#             output_anchor_D_1,output_positive_D_1,output_negative_D_1 = COVID_DR_model(\n",
    "#                     selected_image_a_D,selected_mask_a_D,selected_map_a_D,\n",
    "#                     selected_image_p_D,selected_mask_p_D,selected_map_p_D,selected_image_n_D,selected_mask_n_D,selected_map_n_D,\n",
    "#                     image_positive_R,mask_positive_R,map_positive_R,image_negative_R,mask_negative_R,map_negative_R)\n",
    "            \n",
    "            #compute loss\n",
    "            triplet_loss_val_D = criterion_1(output_anchor_D,output_positive_D,output_negative_D)\n",
    "            \n",
    "#             predicted_labels = torch.cat([output_anchor_D_1,output_positive_D_1,output_negative_D_1])\n",
    "#             true_labels = torch.cat([selected_label_p.cuda(),selected_label_p.cuda(),selected_label_n.cuda()])\n",
    "            output_anchor_D_1 = COVID_DR_model.module.classification(output_anchor_D)\n",
    "            output_positive_D_1 = COVID_DR_model.module.classification(output_positive_D)\n",
    "            output_negative_D_1 = COVID_DR_model.module.classification(output_negative_D)\n",
    "            CE_loss_val_D = criterion_2(output_anchor_D_1,label_anchor)+ \\\n",
    "                        criterion_2(output_positive_D_1,label_positive)+ \\\n",
    "                        criterion_2(output_negative_D_1,label_negative)\n",
    "#             CE_loss_val_D = criterion_2(output_anchor_D_1.view(-1, 1),label_anchor.view(-1, 1))+ \\\n",
    "#                             criterion_2(output_positive_D_1.view(-1, 1),label_positive.view(-1, 1))+ \\\n",
    "#                             criterion_2(output_negative_D_1.view(-1, 1),label_negative.view(-1, 1))\n",
    "#             CE_loss_val_D = criterion_2(predicted_labels.cuda(),true_labels.cuda())\n",
    "            ############ for Retrival\n",
    "            # Choose the hard negatives\n",
    "#             d_p_R = l2_dist.forward(output_anchor_R, output_positive_R)\n",
    "#             d_n_R = l2_dist.forward(output_anchor_R, output_negative_R)\n",
    "#             all_R = (d_n_R - d_p_R < margin).cpu().data.numpy().flatten()\n",
    "#             hard_triplets_R = np.where(all_R == 1)\n",
    "#             if len(hard_triplets_R[0]) == 0:\n",
    "#                 continue\n",
    "#             out_selected_a_R = Variable(torch.from_numpy(output_anchor_R.cpu().data.numpy()[hard_triplets_R]).cuda())\n",
    "#             out_selected_p_R = Variable(torch.from_numpy(output_positive_R.cpu().data.numpy()[hard_triplets_R]).cuda())\n",
    "#             out_selected_n_R = Variable(torch.from_numpy(output_negative_R.cpu().data.numpy()[hard_triplets_R]).cuda())\n",
    "            #compute loss\n",
    "            triplet_loss_val_R = criterion_1(output_anchor_R,output_positive_R,output_negative_R)\n",
    "            \n",
    "            \n",
    "            \n",
    "#             loss_val_D=triplet_loss_val_D + CE_loss_val_D\n",
    "#             loss_val_D=triplet_loss_val_D\n",
    "#             loss_val_R=triplet_loss_val_R\n",
    "            loss_val = 0.3*(0.4*triplet_loss_val_D+0.6*CE_loss_val_D)+0.7*triplet_loss_val_R\n",
    "    scheduler.step()\n",
    "#     print('Triplet_Loss_Detection_train: {}'.format(triplet_loss_train_D))\n",
    "#     print('CE_Loss_train: {}'.format(CE_loss_train_D))\n",
    "    print('Train_Detection_CE_Loss: {}'.format(CE_loss_train_D))\n",
    "    print('Train_Detection_Loss: {}'.format(triplet_loss_train_D))\n",
    "    print('#########')\n",
    "    print('Train_Recommendation_Loss: {}'.format(triplet_loss_train_R))\n",
    "    print('Train_Loss: {}'.format(loss_train))\n",
    "    print('#####################')\n",
    "#     print('Triplet_Loss_Detection_val: {}'.format(triplet_loss_val_D))\n",
    "    print('Val_Detection_CE_Loss: {}'.format(CE_loss_val_D))\n",
    "    print('Val_Detection_Loss: {}'.format(triplet_loss_val_D))\n",
    "    print('#########')\n",
    "    print('Val_Recommendation_Loss: {}'.format(triplet_loss_val_R))\n",
    "    print('Val_Loss: {}'.format(loss_val))\n",
    "    print('$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$')\n",
    "#     writer.add_scalar('train_loss',loss_train, epoch)\n",
    "#     writer.add_scalar('val_loss',loss_val, epoch)\n",
    "    if epoch%10==0:\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': COVID_DR_model.module.state_dict(),\n",
    "            }, checkpoint='/data2/Cpeng/model_COVID_DR', snapshot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bronze-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=24\n",
    "path = NCP_train[index]\n",
    "test_image = cv2.imread(path,0)\n",
    "test_image = cv2.resize(test_image,(224,224), interpolation=cv2.INTER_CUBIC)\n",
    "test_image = test_image-test_image.min()\n",
    "test_image = (test_image/test_image.max()).astype(np.float32)\n",
    "plt.imshow(test_image)\n",
    "test_image_ = torch.from_numpy(test_image[np.newaxis,np.newaxis,...]).cuda()\n",
    "print(type(test_image_))\n",
    "image_type = path.split('/')[-2].split('_')[0]\n",
    "print(image_type)\n",
    "if image_type == 'NCP':\n",
    "    mask_path = os.path.join('/data2/Cpeng/NCP_lung_masks/',path.split('/')[-1])\n",
    "elif image_type == 'CP':\n",
    "    mask_path = os.path.join('/data2/Cpeng/CP_lung_masks/',path.split('/')[-1])\n",
    "else:\n",
    "    mask_path = os.path.join('/data2/Cpeng/Normal_lung_masks/',path.split('/')[-1])\n",
    "mask = cv2.imread(mask_path,0)\n",
    "mask = cv2.resize(mask,(224,224), interpolation=cv2.INTER_CUBIC)\n",
    "mask[mask>0]=1.\n",
    "mask = mask.astype(np.float32)\n",
    "plt.figure()\n",
    "plt.imshow(mask)\n",
    "mask_map = scipy.ndimage.distance_transform_edt(mask)\n",
    "mask_map = (mask_map/mask_map.max()).astype(np.float32)\n",
    "plt.figure()\n",
    "plt.imshow(mask_map)\n",
    "mask_ = torch.from_numpy(mask[np.newaxis,np.newaxis,...]).cuda()\n",
    "mask_map_ = torch.from_numpy(mask_map[np.newaxis,np.newaxis,...]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bibliographic-welcome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9845, 0.0155]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[ 0.4030,  0.1717, -0.2607,  0.0182,  0.5311, -0.8104, -0.0843,  0.3068,\n",
      "         -0.7838, -0.2688, -0.1498,  0.3320,  0.1315,  0.4377,  0.3430,  1.0309,\n",
      "         -0.7670,  0.7076,  0.0818,  0.2519,  0.3087, -0.3093, -0.7321,  0.9076,\n",
      "          0.4248,  0.1441,  0.4799, -0.4326, -0.3921,  0.9561,  0.2539, -0.3004,\n",
      "         -0.2766, -0.4824, -0.3906, -0.0180, -0.4645,  0.9989,  0.2780, -0.2343,\n",
      "         -0.2929,  0.2809, -0.0876, -0.3067, -0.2799, -0.3968, -0.2292, -0.3067,\n",
      "          0.0908, -0.4303,  0.7445,  0.1691, -0.0073,  0.3704,  0.3450, -0.2669,\n",
      "          0.1401, -0.3687,  0.6973,  0.3545, -0.3329,  0.2113,  0.2049,  0.1024,\n",
      "         -0.5781, -0.5623, -0.1788, -0.1551, -0.0813, -0.0860,  0.1842, -0.1160,\n",
      "         -0.2571,  0.2024, -0.3429, -0.1812, -0.0159, -0.3434,  0.2976, -0.0879,\n",
      "          0.6142,  0.3036, -0.2015, -0.3351, -0.2978, -1.1246, -0.1829,  0.3965,\n",
      "         -0.6307, -0.1248, -0.3157, -0.1400, -0.4593, -0.2148, -0.5557,  0.2938,\n",
      "         -0.3138, -0.5589, -0.1564, -0.3593, -0.2617, -0.2416, -0.2620,  0.4106,\n",
      "         -0.3199, -0.1385,  0.2962,  0.5212, -0.2895, -0.1615, -0.3484, -0.2626,\n",
      "          0.1499,  0.1912, -0.3409,  0.7478,  0.5294, -0.1200, -0.8025, -0.3451,\n",
      "         -0.1041, -0.2685,  0.1418, -0.3818, -0.6186, -0.4449, -0.0393,  0.7677]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "COVID_DR_model = COVID_CR_network()\n",
    "checkpoint = torch.load('/data2/Cpeng/model_COVID_DR/checkpoint_30.pth.tar', map_location=\"cuda:0\")\n",
    "COVID_DR_model.load_state_dict(checkpoint['state_dict'])\n",
    "COVID_DR_model.cuda()\n",
    "output_anchor_D,output_positive_D,output_negative_D,output_anchor_R,output_positive_R,output_negative_R = \\\n",
    "        COVID_DR_model(test_image_,mask_,mask_map_,\n",
    "                   test_image_,mask_,mask_map_,\n",
    "                   test_image_,mask_,mask_map_,\n",
    "                   test_image_,mask_,mask_map_,\n",
    "                   test_image_,mask_,mask_map_)\n",
    "output_anchor_D_1 =COVID_DR_model.classification(output_anchor_D) \n",
    "print(torch.softmax(output_anchor_D_1,dim=1))\n",
    "print(output_anchor_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-plasma",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-converter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
