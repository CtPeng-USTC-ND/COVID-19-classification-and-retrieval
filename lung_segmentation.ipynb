{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eleven-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from lung_segmentation_network import UNet\n",
    "from skimage import morphology\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "CT_images = glob.glob('/data2/Cpeng/CT_images_lung_segmentation/*.jpg')\n",
    "print(len(CT_images))\n",
    "# lung_masks = glob.glob('/data2/Cpeng/lung_masks/*.jpg')\n",
    "# print(len(lung_masks))  #3520 original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "passing-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv2.imread(CT_images[300],0)\n",
    "# plt.imshow(image)\n",
    "# print(image.shape)\n",
    "# print(image.max())\n",
    "# print(image.min())\n",
    "\n",
    "# mask = cv2.imread(lung_masks[300],0)\n",
    "# plt.figure()\n",
    "# plt.imshow(mask)\n",
    "# print(mask.shape)\n",
    "# print(mask.max())\n",
    "# print(mask.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "optical-feature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X,test_X,_,_ = train_test_split(CT_images,CT_images,test_size = 0.01, random_state = 42)\n",
    "print(len(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "oriented-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "class Lung_segmentation(Dataset):\n",
    "    def __init__(self, file_path_list, phase='train'):\n",
    "        self.path_list = file_path_list\n",
    "        self.phase = phase\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image, label= self.load_data(self.path_list[index])\n",
    "        image, label = self.process_data(image, label)\n",
    "        \n",
    "        return image, label\n",
    "        \n",
    "    def load_data(self, file_path):\n",
    "        image = cv2.imread(file_path,0)\n",
    "        label_path = os.path.join('/data2/Cpeng/lung_masks/',file_path.split('/')[-1])\n",
    "        label = cv2.imread(label_path,0)\n",
    "        \n",
    "        image = cv2.resize(image, (256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "        image = image-image.min()\n",
    "        image = (image/image.max()).astype(np.float32)\n",
    "        label = cv2.resize(label, (256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "        if label.max()>0:\n",
    "            label = (label/label.max()).astype(np.float32)\n",
    "        else:\n",
    "            label = label.astype(np.float32)\n",
    "        return image, label\n",
    "        \n",
    "    def process_data(self, *args):\n",
    "        return [item[np.newaxis, :, :].astype(np.float32) for item in args]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sound-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device('cpu' if not torch.cuda.is_available() else 'cuda')\n",
    "batch_size = 16\n",
    "num_workers = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unable-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Lung_segmentation(file_path_list=train_X, phase='train')\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "valset = Lung_segmentation(file_path_list=test_X, phase='test')\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "reverse-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dice_loss import *\n",
    "segmentation_model = UNet(1,1).cuda()\n",
    "checkpoint = torch.load('/data2/Cpeng/model_lung_segmentation/checkpoint_{}.pth.tar'.format(240), map_location=\"cuda:0\")\n",
    "segmentation_model.load_state_dict(checkpoint['state_dict'])\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import *\n",
    "criterion = DiceLoss().cuda()\n",
    "optimizer = torch.optim.Adam(segmentation_model.parameters(), lr=1e-3)\n",
    "scheduler = StepLR(optimizer, 20, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "front-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(segmentation_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acknowledged-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, checkpoint='checkpoint', snapshot=1):\n",
    "    if not os.path.exists(checkpoint): os.makedirs(checkpoint)\n",
    "    if snapshot and state['epoch'] % snapshot == 0:\n",
    "        torch.save(state, os.path.join(checkpoint, 'checkpoint_{}.pth.tar'.format(state['epoch'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "surprised-butterfly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pengchengtao/pct3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:82: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Loss: tensor([0.1184], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0319], device='cuda:0')\n",
      "epoch:242\n",
      "Train_Loss: tensor([0.0204], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0233], device='cuda:0')\n",
      "epoch:243\n",
      "Train_Loss: tensor([0.2199], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0275], device='cuda:0')\n",
      "epoch:244\n",
      "Train_Loss: tensor([0.0666], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0416], device='cuda:0')\n",
      "epoch:245\n",
      "Train_Loss: tensor([0.0197], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0252], device='cuda:0')\n",
      "epoch:246\n",
      "Train_Loss: tensor([0.0276], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0248], device='cuda:0')\n",
      "epoch:247\n",
      "Train_Loss: tensor([0.0388], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0256], device='cuda:0')\n",
      "epoch:248\n",
      "Train_Loss: tensor([0.0879], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0205], device='cuda:0')\n",
      "epoch:249\n",
      "Train_Loss: tensor([0.0196], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0233], device='cuda:0')\n",
      "epoch:250\n",
      "Train_Loss: tensor([0.0123], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0202], device='cuda:0')\n",
      "epoch:251\n",
      "Train_Loss: tensor([0.0346], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0313], device='cuda:0')\n",
      "epoch:252\n",
      "Train_Loss: tensor([0.0693], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0373], device='cuda:0')\n",
      "epoch:253\n",
      "Train_Loss: tensor([0.0417], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0249], device='cuda:0')\n",
      "epoch:254\n",
      "Train_Loss: tensor([0.0802], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0366], device='cuda:0')\n",
      "epoch:255\n",
      "Train_Loss: tensor([0.0363], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0337], device='cuda:0')\n",
      "epoch:256\n",
      "Train_Loss: tensor([0.3800], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0299], device='cuda:0')\n",
      "epoch:257\n",
      "Train_Loss: tensor([0.0405], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0250], device='cuda:0')\n",
      "epoch:258\n",
      "Train_Loss: tensor([0.0940], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0226], device='cuda:0')\n",
      "epoch:259\n",
      "Train_Loss: tensor([0.0201], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0261], device='cuda:0')\n",
      "epoch:260\n",
      "Train_Loss: tensor([0.0191], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0295], device='cuda:0')\n",
      "epoch:261\n",
      "Train_Loss: tensor([0.0250], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0201], device='cuda:0')\n",
      "epoch:262\n",
      "Train_Loss: tensor([0.0374], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0227], device='cuda:0')\n",
      "epoch:263\n",
      "Train_Loss: tensor([0.0267], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0235], device='cuda:0')\n",
      "epoch:264\n",
      "Train_Loss: tensor([0.0303], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0221], device='cuda:0')\n",
      "epoch:265\n",
      "Train_Loss: tensor([0.0336], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0200], device='cuda:0')\n",
      "epoch:266\n",
      "Train_Loss: tensor([0.0749], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0229], device='cuda:0')\n",
      "epoch:267\n",
      "Train_Loss: tensor([0.0214], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0223], device='cuda:0')\n",
      "epoch:268\n",
      "Train_Loss: tensor([0.0224], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0319], device='cuda:0')\n",
      "epoch:269\n",
      "Train_Loss: tensor([0.0279], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0245], device='cuda:0')\n",
      "epoch:270\n",
      "Train_Loss: tensor([0.0692], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0229], device='cuda:0')\n",
      "epoch:271\n",
      "Train_Loss: tensor([0.0900], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0196], device='cuda:0')\n",
      "epoch:272\n",
      "Train_Loss: tensor([0.0310], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0261], device='cuda:0')\n",
      "epoch:273\n",
      "Train_Loss: tensor([0.0234], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0181], device='cuda:0')\n",
      "epoch:274\n",
      "Train_Loss: tensor([0.0219], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0154], device='cuda:0')\n",
      "epoch:275\n",
      "Train_Loss: tensor([0.0690], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0213], device='cuda:0')\n",
      "epoch:276\n",
      "Train_Loss: tensor([0.0245], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0197], device='cuda:0')\n",
      "epoch:277\n",
      "Train_Loss: tensor([0.0312], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0253], device='cuda:0')\n",
      "epoch:278\n",
      "Train_Loss: tensor([0.0765], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0230], device='cuda:0')\n",
      "epoch:279\n",
      "Train_Loss: tensor([0.2239], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0249], device='cuda:0')\n",
      "epoch:280\n",
      "Train_Loss: tensor([0.0203], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0167], device='cuda:0')\n",
      "epoch:281\n",
      "Train_Loss: tensor([0.0150], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0198], device='cuda:0')\n",
      "epoch:282\n",
      "Train_Loss: tensor([0.0282], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0317], device='cuda:0')\n",
      "epoch:283\n",
      "Train_Loss: tensor([0.1151], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0188], device='cuda:0')\n",
      "epoch:284\n",
      "Train_Loss: tensor([0.0406], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0237], device='cuda:0')\n",
      "epoch:285\n",
      "Train_Loss: tensor([0.0107], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0250], device='cuda:0')\n",
      "epoch:286\n",
      "Train_Loss: tensor([0.0386], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0167], device='cuda:0')\n",
      "epoch:287\n",
      "Train_Loss: tensor([0.0211], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0175], device='cuda:0')\n",
      "epoch:288\n",
      "Train_Loss: tensor([0.0125], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0249], device='cuda:0')\n",
      "epoch:289\n",
      "Train_Loss: tensor([0.0168], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0206], device='cuda:0')\n",
      "epoch:290\n",
      "Train_Loss: tensor([0.0156], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0169], device='cuda:0')\n",
      "epoch:291\n",
      "Train_Loss: tensor([0.3952], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0272], device='cuda:0')\n",
      "epoch:292\n",
      "Train_Loss: tensor([0.0290], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0219], device='cuda:0')\n",
      "epoch:293\n",
      "Train_Loss: tensor([0.0146], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0240], device='cuda:0')\n",
      "epoch:294\n",
      "Train_Loss: tensor([0.0116], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0172], device='cuda:0')\n",
      "epoch:295\n",
      "Train_Loss: tensor([0.2270], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0173], device='cuda:0')\n",
      "epoch:296\n",
      "Train_Loss: tensor([0.0226], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0175], device='cuda:0')\n",
      "epoch:297\n",
      "Train_Loss: tensor([0.0227], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0181], device='cuda:0')\n",
      "epoch:298\n",
      "Train_Loss: tensor([0.0114], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0216], device='cuda:0')\n",
      "epoch:299\n",
      "Train_Loss: tensor([0.0255], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0165], device='cuda:0')\n",
      "epoch:300\n",
      "Train_Loss: tensor([0.0408], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0179], device='cuda:0')\n",
      "epoch:301\n",
      "Train_Loss: tensor([0.0284], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0185], device='cuda:0')\n",
      "epoch:302\n",
      "Train_Loss: tensor([0.0307], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0224], device='cuda:0')\n",
      "epoch:303\n",
      "Train_Loss: tensor([0.0982], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0177], device='cuda:0')\n",
      "epoch:304\n",
      "Train_Loss: tensor([0.0396], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0195], device='cuda:0')\n",
      "epoch:305\n",
      "Train_Loss: tensor([0.0218], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0191], device='cuda:0')\n",
      "epoch:306\n",
      "Train_Loss: tensor([0.0255], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0201], device='cuda:0')\n",
      "epoch:307\n",
      "Train_Loss: tensor([0.0166], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0228], device='cuda:0')\n",
      "epoch:308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Loss: tensor([0.2056], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0212], device='cuda:0')\n",
      "epoch:309\n",
      "Train_Loss: tensor([0.0270], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0191], device='cuda:0')\n",
      "epoch:310\n",
      "Train_Loss: tensor([0.0180], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0208], device='cuda:0')\n",
      "epoch:311\n",
      "Train_Loss: tensor([0.0079], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0201], device='cuda:0')\n",
      "epoch:312\n",
      "Train_Loss: tensor([0.0172], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0250], device='cuda:0')\n",
      "epoch:313\n",
      "Train_Loss: tensor([0.0131], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0239], device='cuda:0')\n",
      "epoch:314\n",
      "Train_Loss: tensor([0.0209], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0195], device='cuda:0')\n",
      "epoch:315\n",
      "Train_Loss: tensor([0.0213], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0203], device='cuda:0')\n",
      "epoch:316\n",
      "Train_Loss: tensor([0.0116], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0191], device='cuda:0')\n",
      "epoch:317\n",
      "Train_Loss: tensor([0.0256], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0165], device='cuda:0')\n",
      "epoch:318\n",
      "Train_Loss: tensor([0.0346], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0157], device='cuda:0')\n",
      "epoch:319\n",
      "Train_Loss: tensor([0.0127], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0227], device='cuda:0')\n",
      "epoch:320\n",
      "Train_Loss: tensor([0.0619], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0185], device='cuda:0')\n",
      "epoch:321\n",
      "Train_Loss: tensor([0.0685], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0239], device='cuda:0')\n",
      "epoch:322\n",
      "Train_Loss: tensor([0.0165], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0191], device='cuda:0')\n",
      "epoch:323\n",
      "Train_Loss: tensor([0.0118], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0159], device='cuda:0')\n",
      "epoch:324\n",
      "Train_Loss: tensor([0.0130], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0185], device='cuda:0')\n",
      "epoch:325\n",
      "Train_Loss: tensor([0.0450], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0213], device='cuda:0')\n",
      "epoch:326\n",
      "Train_Loss: tensor([0.0320], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0231], device='cuda:0')\n",
      "epoch:327\n",
      "Train_Loss: tensor([0.0135], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0195], device='cuda:0')\n",
      "epoch:328\n",
      "Train_Loss: tensor([0.0835], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0180], device='cuda:0')\n",
      "epoch:329\n",
      "Train_Loss: tensor([0.0290], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0219], device='cuda:0')\n",
      "epoch:330\n",
      "Train_Loss: tensor([0.0194], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0233], device='cuda:0')\n",
      "epoch:331\n",
      "Train_Loss: tensor([0.0175], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0171], device='cuda:0')\n",
      "epoch:332\n",
      "Train_Loss: tensor([0.0202], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0213], device='cuda:0')\n",
      "epoch:333\n",
      "Train_Loss: tensor([0.0198], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0173], device='cuda:0')\n",
      "epoch:334\n",
      "Train_Loss: tensor([0.1197], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0195], device='cuda:0')\n",
      "epoch:335\n",
      "Train_Loss: tensor([0.0421], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0233], device='cuda:0')\n",
      "epoch:336\n",
      "Train_Loss: tensor([0.0433], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0214], device='cuda:0')\n",
      "epoch:337\n",
      "Train_Loss: tensor([0.0228], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0198], device='cuda:0')\n",
      "epoch:338\n",
      "Train_Loss: tensor([0.0688], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0154], device='cuda:0')\n",
      "epoch:339\n",
      "Train_Loss: tensor([0.0192], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0166], device='cuda:0')\n",
      "epoch:340\n",
      "Train_Loss: tensor([0.0450], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0231], device='cuda:0')\n",
      "epoch:341\n",
      "Train_Loss: tensor([0.1076], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0214], device='cuda:0')\n",
      "epoch:342\n",
      "Train_Loss: tensor([0.0203], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0220], device='cuda:0')\n",
      "epoch:343\n",
      "Train_Loss: tensor([0.0164], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0229], device='cuda:0')\n",
      "epoch:344\n",
      "Train_Loss: tensor([0.0226], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0230], device='cuda:0')\n",
      "epoch:345\n",
      "Train_Loss: tensor([0.0160], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0215], device='cuda:0')\n",
      "epoch:346\n",
      "Train_Loss: tensor([0.0713], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0210], device='cuda:0')\n",
      "epoch:347\n",
      "Train_Loss: tensor([0.0371], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0170], device='cuda:0')\n",
      "epoch:348\n",
      "Train_Loss: tensor([0.0685], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0274], device='cuda:0')\n",
      "epoch:349\n",
      "Train_Loss: tensor([0.0170], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0183], device='cuda:0')\n",
      "epoch:350\n",
      "Train_Loss: tensor([0.0452], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0131], device='cuda:0')\n",
      "epoch:351\n",
      "Train_Loss: tensor([0.0145], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0184], device='cuda:0')\n",
      "epoch:352\n",
      "Train_Loss: tensor([0.1149], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0197], device='cuda:0')\n",
      "epoch:353\n",
      "Train_Loss: tensor([0.0339], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0161], device='cuda:0')\n",
      "epoch:354\n",
      "Train_Loss: tensor([0.1485], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0145], device='cuda:0')\n",
      "epoch:355\n",
      "Train_Loss: tensor([0.0375], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0183], device='cuda:0')\n",
      "epoch:356\n",
      "Train_Loss: tensor([0.0415], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0185], device='cuda:0')\n",
      "epoch:357\n",
      "Train_Loss: tensor([0.0829], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0146], device='cuda:0')\n",
      "epoch:358\n",
      "Train_Loss: tensor([0.0272], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0211], device='cuda:0')\n",
      "epoch:359\n",
      "Train_Loss: tensor([0.0224], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0201], device='cuda:0')\n",
      "epoch:360\n",
      "Train_Loss: tensor([0.0245], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0170], device='cuda:0')\n",
      "epoch:361\n",
      "Train_Loss: tensor([0.0382], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0138], device='cuda:0')\n",
      "epoch:362\n",
      "Train_Loss: tensor([0.0108], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0202], device='cuda:0')\n",
      "epoch:363\n",
      "Train_Loss: tensor([0.0377], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0179], device='cuda:0')\n",
      "epoch:364\n",
      "Train_Loss: tensor([0.0147], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0222], device='cuda:0')\n",
      "epoch:365\n",
      "Train_Loss: tensor([0.2856], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Val_Loss: tensor([0.0183], device='cuda:0')\n",
      "epoch:366\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4e4277f51029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msegmentation_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegmentation_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-4e4277f51029>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msegmentation_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegmentation_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "step=0\n",
    "epoches=421\n",
    "\n",
    "for epoch in range(241,epoches):\n",
    "    print('epoch:' + str(epoch))\n",
    "    scheduler.step()\n",
    "    loss_train=0.0\n",
    "    loss_val=0.0\n",
    "    segmentation_model.train()\n",
    "    for i,data in enumerate(train_loader):\n",
    "        image, label = [item.to(device) for item in data]\n",
    "        output = segmentation_model(image)\n",
    "        loss_train=criterion(output,label.float())\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        segmentation_model.eval()\n",
    "        for i,data in enumerate(val_loader):\n",
    "            image, label = [item.to(device) for item in data]\n",
    "            output= segmentation_model(image)\n",
    "            loss_val=criterion(output,label.float())\n",
    "    print('Train_Loss: {}'.format(loss_train))\n",
    "    print('Val_Loss: {}'.format(loss_val))\n",
    "#     writer.add_scalar('train_loss',loss_train, epoch)\n",
    "#     writer.add_scalar('val_loss',loss_val, epoch)\n",
    "    if epoch%10==0:\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': segmentation_model.state_dict(),\n",
    "            }, checkpoint='/data2/Cpeng/model_lung_segmentation', snapshot=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/data2/Cpeng/results/'+str(10)+'_image.jpg'\n",
    "cv2.imwrite(image_path,image)\n",
    "mask_path = '/data2/Cpeng/results/'+str(10)+'_mask.jpg'\n",
    "cv2.imwrite(mask_path,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "spatial-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('/data2/Cpeng/NCP_raw_images/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "driving-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = images[180]\n",
    "image=cv2.imread(image_path,0)\n",
    "mask_path = '/data2/Cpeng/NCP_lung_masks/'+image_path.split('/')[-1]\n",
    "mask = cv2.imread(mask_path,0)\n",
    "plt.imshow(image)\n",
    "plt.figure()\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image = '/data2/Cpeng/results/180_image.jpg'\n",
    "cv2.imwrite(save_image,image)\n",
    "save_mask = '/data2/Cpeng/results/180_mask.jpg'\n",
    "cv2.imwrite(save_mask,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "wireless-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "lung_image = image*mask\n",
    "plt.imshow(lung_image)\n",
    "save_lung_image= '/data2/Cpeng/results/180_lung_image.jpg'\n",
    "cv2.imwrite(save_lung_image,lung_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "coordinate-guess",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_image = '/data2/Cpeng/results/180_image.jpg'\n",
    "cv2.imwrite(save_image,image)\n",
    "save_mask = '/data2/Cpeng/results/180_mask.jpg'\n",
    "cv2.imwrite(save_mask,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "specialized-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "mask[mask>0]=1\n",
    "mt = scipy.ndimage.distance_transform_edt(mask)\n",
    "plt.imshow(mt,cmap='gray')\n",
    "save_map = '/data2/Cpeng/results/180_map.jpg'\n",
    "cv2.imwrite(save_map,mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-answer",
   "metadata": {},
   "source": [
    "# dice计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "incident-father",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data2/Cpeng/CT_images_lung_segmentation/coronacases_004_116.jpg\n"
     ]
    }
   ],
   "source": [
    "from dice_loss import *\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device('cpu' if not torch.cuda.is_available() else 'cuda')\n",
    "segmentation_model = UNet(1,1).cuda()\n",
    "test=[]\n",
    "test.append(test_X[10])\n",
    "print(test_X[10])\n",
    "ts = Lung_segmentation(file_path_list=test,phase = 'test')\n",
    "loader = torch.utils.data.DataLoader(ts, batch_size=8, shuffle=True, num_workers=8, drop_last=True)\n",
    "valset = Lung_segmentation(file_path_list=test_X, phase='test')\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=1, shuffle=True, num_workers=1)\n",
    "checkpoint = torch.load('/data2/Cpeng/model_lung_segmentation/checkpoint_{}.pth.tar'.format(200), map_location=\"cuda:0\")\n",
    "segmentation_model.load_state_dict(checkpoint['state_dict'])\n",
    "DS=0.0\n",
    "num=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fluid-chuck",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(val_loader):\n",
    "        image, label = [item.to(device) for item in data]\n",
    "        output = segmentation_model(image)\n",
    "    #     output = torch.sigmoid(output)\n",
    "    #     output[output>0.1]=1.0\n",
    "    #     output[output<0.1]=0.0\n",
    "    #     print(type(output))\n",
    "    #     print(output)\n",
    "        DS = DS + DiceScore()(output,label.float())\n",
    "#         print(DS)\n",
    "        num = num +1\n",
    "print('Dice_Score:{}'.format(DS/num))\n",
    "output=output[0,0,...].cpu().detach().numpy()\n",
    "label=label[0,0,...].cpu().detach().numpy()\n",
    "image=image[0,0,...].cpu().detach().numpy()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(output,cmap='gray')\n",
    "plt.figure()\n",
    "output[output>0.1]=1\n",
    "output[output<0.1]=0\n",
    "plt.imshow(output,cmap='gray')\n",
    "plt.figure()\n",
    "plt.imshow(label)\n",
    "plt.figure()\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-highway",
   "metadata": {},
   "source": [
    "# DS: 0.1-0.9661 0.5-0.9669"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-livestock",
   "metadata": {},
   "source": [
    "# 模型推理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-overview",
   "metadata": {},
   "source": [
    "# NCP images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "twelve-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "class Lung_segmentation_1(Dataset):\n",
    "    def __init__(self, file_path_list, phase='train'):\n",
    "        self.path_list = file_path_list\n",
    "        self.phase = phase\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image= self.load_data(self.path_list[index])\n",
    "        image = self.process_data(image)\n",
    "        \n",
    "        return image, self.path_list[index]\n",
    "        \n",
    "    def load_data(self, file_path):\n",
    "        image = cv2.imread(file_path,0)\n",
    "        image = cv2.resize(image, (256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "        image = image-image.min()\n",
    "        image = (image/image.max()).astype(np.float32)\n",
    "        \n",
    "        return image\n",
    "        \n",
    "    def process_data(self, *args):\n",
    "        return [item[np.newaxis, :, :].astype(np.float32) for item in args]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "attended-study",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCP/1010/2572/0013.JPG\n",
      "(512, 512)\n",
      "72\n",
      "255\n",
      "21310\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# lesion_slices_dir = \"/data2/Cpeng/COVID/\"\n",
    "# lesion_slices = pd.read_csv('/data2/Cpeng/COVID/lesions_slices.csv')\n",
    "# NCP_slices = lesion_slices['imgpath'].tolist()[36894:58766]\n",
    "# print(NCP_slices[0])\n",
    "# print(len(NCP_slices))\n",
    "# NCP_image_dir = '/data2/Cpeng/COVID/'\n",
    "# test_image = cv2.imread(lesion_slices_dir+NCP_slices[0],0)\n",
    "# print(test_image.shape)\n",
    "# print(test_image.min())\n",
    "# print(test_image.max())\n",
    "# NCP_slices_raw = []\n",
    "# for i in range(len(NCP_slices)):\n",
    "#     if os.path.exists(lesion_slices_dir+NCP_slices[i]):\n",
    "#         NCP_slices_raw.append(lesion_slices_dir+NCP_slices[i])\n",
    "# print(len(NCP_slices_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adjacent-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NCP_raw_images_file = '/data2/Cpeng/COVID/NCP_raw_images.csv'\n",
    "# df = pd.DataFrame(NCP_slices_raw)\n",
    "# df.to_csv(NCP_raw_images_file,index=None,header='imgpath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "elect-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "NCP_slices = pd.read_csv('/data2/Cpeng/COVID/NCP_raw_images.csv')\n",
    "NCP_slices_raw = NCP_slices['0'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "oriented-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NCP_slices_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "perfect-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save image slices\n",
    "images = glob.glob('/data2/Cpeng/NCP_raw_images/*')\n",
    "print(len(images))\n",
    "print(images[0])\n",
    "for i in range(len(images)):\n",
    "    image = cv2.imread(images[i],0)\n",
    "    path_ = ('/').join(images[i].split('/')[-1].split('_')[0:3])\n",
    "    save_path_ = os.path.join('/data2/Cpeng/NCP_raw_images_patients/',('/').join(images[i].split('/')[-1].split('_')[0:2]))\n",
    "    print(save_path_)\n",
    "    if not os.path.exists(save_path_):\n",
    "        os.makedirs(save_path_)\n",
    "    save_path = os.path.join('/data2/Cpeng/NCP_raw_images_patients/',('/').join(images[i].split('/')[-1].split('_')[0:3]))\n",
    "#     print(save_path)\n",
    "#     break\n",
    "    cv2.imwrite(save_path,image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "equal-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device('cpu' if not torch.cuda.is_available() else 'cuda')\n",
    "segmentation_model = UNet(1,1).cuda()\n",
    "checkpoint = torch.load('/data2/Cpeng/model_lung_segmentation/checkpoint_{}.pth.tar'.format(360), map_location=\"cuda:0\")\n",
    "segmentation_model.load_state_dict(checkpoint['state_dict'])\n",
    "valset = Lung_segmentation_1(file_path_list=NCP_slices_raw, phase='test')\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=40, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "permanent-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_model.eval()\n",
    "COVID_lung_masks_dir = \"/data2/Cpeng/NCP_lung_masks/\"\n",
    "COVID_images_dir = \"/data2/Cpeng/NCP_raw_images/\"\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(val_loader):\n",
    "        image,path= data\n",
    "        image = image[0].cuda()\n",
    "#         print(path)\n",
    "        output = segmentation_model(image)\n",
    "        output = torch.sigmoid(output)\n",
    "        output[output>0.5]=1.0\n",
    "        output[output<0.5]=0.0\n",
    "        output=output.cpu().detach().numpy()\n",
    "#         output = (output*255).astype(np.uint8)\n",
    "        image=image.cpu().detach().numpy()\n",
    "        for j in range(output.shape[0]):\n",
    "            mask = output[j,0,...]\n",
    "#             image_ = image[j,0,...]\n",
    "#             plt.imshow(mask)\n",
    "#             plt.figure()\n",
    "            mask = morphology.closing(mask,morphology.square(5))\n",
    "            mask[mask>0]=1.\n",
    "            mask = mask*255\n",
    "#             plt.imshow(mask)\n",
    "#             plt.figure()\n",
    "#             plt.imshow(image_)\n",
    "            image_ = image[j,0,...]\n",
    "            image_ = image_*255\n",
    "            save_name_mask = os.path.join(COVID_lung_masks_dir,('_').join(path[j].split('/')[5:8]))\n",
    "            save_name_image = os.path.join(COVID_images_dir,('_').join(path[j].split('/')[5:8]))\n",
    "#             print(save_name)\n",
    "#             break\n",
    "#         break\n",
    "            cv2.imwrite(save_name_mask,mask)\n",
    "            cv2.imwrite(save_name_image,image_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-november",
   "metadata": {},
   "source": [
    "# CP images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caroline-symphony",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save image slices\n",
    "images = glob.glob('/data2/Cpeng/CP_raw_images/*')\n",
    "print(len(images))\n",
    "print(images[0])\n",
    "for i in range(len(images)):\n",
    "    image = cv2.imread(images[i],0)\n",
    "    path_ = ('/').join(images[i].split('/')[-1].split('_')[0:3])\n",
    "    save_path_ = os.path.join('/data2/Cpeng/CP_raw_images_patients/',('/').join(images[i].split('/')[-1].split('_')[0:2]))\n",
    "#     print(save_path_)\n",
    "    if not os.path.exists(save_path_):\n",
    "        os.makedirs(save_path_)\n",
    "    save_path = os.path.join('/data2/Cpeng/CP_raw_images_patients/',('/').join(images[i].split('/')[-1].split('_')[0:3]))\n",
    "#     print(save_path)\n",
    "#     break\n",
    "    cv2.imwrite(save_path,image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "figured-blast",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CP/3783/5727/0008.png\n",
      "36894\n",
      "(512, 512)\n",
      "37\n",
      "255\n",
      "36781\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "lesion_slices_dir = \"/data2/Cpeng/COVID/\"\n",
    "lesion_slices = pd.read_csv('/data2/Cpeng/COVID/lesions_slices.csv')\n",
    "CP_slices = lesion_slices['imgpath'].tolist()[0:36894]\n",
    "print(CP_slices[0])\n",
    "print(len(CP_slices))\n",
    "CP_image_dir = '/data2/Cpeng/COVID/'\n",
    "test_image = cv2.imread(lesion_slices_dir+CP_slices[0],0)\n",
    "print(test_image.shape)\n",
    "print(test_image.min())\n",
    "print(test_image.max())\n",
    "CP_slices_raw = []\n",
    "for i in range(len(CP_slices)):\n",
    "    if os.path.exists(lesion_slices_dir+CP_slices[i]):\n",
    "        CP_slices_raw.append(lesion_slices_dir+CP_slices[i])\n",
    "print(len(CP_slices_raw))\n",
    "\n",
    "CP_raw_images_file = '/data2/Cpeng/COVID/CP_raw_images.csv'\n",
    "df = pd.DataFrame(CP_slices_raw)\n",
    "df.to_csv(CP_raw_images_file,header='imgpath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adaptive-banks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data2/Cpeng/COVID/CP/3783/5727/0008.png\n"
     ]
    }
   ],
   "source": [
    "print(CP_slices_raw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "informal-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "class Lung_segmentation_1(Dataset):\n",
    "    def __init__(self, file_path_list, phase='train'):\n",
    "        self.path_list = file_path_list\n",
    "        self.phase = phase\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image= self.load_data(self.path_list[index])\n",
    "        image = self.process_data(image)\n",
    "        \n",
    "        return image, self.path_list[index]\n",
    "        \n",
    "    def load_data(self, file_path):\n",
    "        image = cv2.imread(file_path,0)\n",
    "        image = cv2.resize(image, (256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "        image = image-image.min()\n",
    "        image = (image/image.max()).astype(np.float32)\n",
    "        \n",
    "        return image\n",
    "        \n",
    "    def process_data(self, *args):\n",
    "        return [item[np.newaxis, :, :].astype(np.float32) for item in args]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "collective-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device('cpu' if not torch.cuda.is_available() else 'cuda')\n",
    "segmentation_model = UNet(1,1).cuda()\n",
    "checkpoint = torch.load('/data2/Cpeng/model_lung_segmentation/checkpoint_{}.pth.tar'.format(360), map_location=\"cuda:0\")\n",
    "segmentation_model.load_state_dict(checkpoint['state_dict'])\n",
    "valset = Lung_segmentation_1(file_path_list=CP_slices_raw, phase='test')\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=40, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "educated-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_model.eval()\n",
    "CP_lung_masks_dir = \"/data2/Cpeng/CP_lung_masks/\"\n",
    "CP_images_dir = \"/data2/Cpeng/CP_raw_images/\"\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(val_loader):\n",
    "        image,path= data\n",
    "        image = image[0].cuda()\n",
    "#         print(path)\n",
    "        output = segmentation_model(image)\n",
    "        output = torch.sigmoid(output)\n",
    "        output[output>0.5]=1.0\n",
    "        output[output<0.5]=0.0\n",
    "        output=output.cpu().detach().numpy()\n",
    "#         output = (output*255).astype(np.uint8)\n",
    "        image=image.cpu().detach().numpy()\n",
    "        for j in range(output.shape[0]):\n",
    "            mask = output[j,0,...]\n",
    "#             image_ = image[j,0,...]\n",
    "#             plt.imshow(mask)\n",
    "#             plt.figure()\n",
    "            mask = morphology.closing(mask,morphology.square(5))\n",
    "            mask[mask>0]=1.\n",
    "            mask = mask*255\n",
    "#             plt.imshow(mask)\n",
    "            \n",
    "            image_ = image[j,0,...]\n",
    "            image_ = image_*255\n",
    "#             plt.figure()\n",
    "#             plt.imshow(image_)\n",
    "            save_name_mask = os.path.join(CP_lung_masks_dir,('_').join(path[j].split('/')[5:8]))\n",
    "            save_name_image = os.path.join(CP_images_dir,('_').join(path[j].split('/')[5:8]))\n",
    "#             print(save_name)\n",
    "#             break\n",
    "#         break\n",
    "            cv2.imwrite(save_name_mask,mask)\n",
    "            cv2.imwrite(save_name_image,image_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-blackberry",
   "metadata": {},
   "source": [
    "# Normal_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "separate-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save image slices\n",
    "images = glob.glob('/data2/Cpeng/Normal_raw_images/*')\n",
    "print(len(images))\n",
    "print(images[0])\n",
    "for i in range(len(images)):\n",
    "    image = cv2.imread(images[i],0)\n",
    "    path_ = ('/').join(images[i].split('/')[-1].split('_')[0:3])\n",
    "    save_path_ = os.path.join('/data2/Cpeng/Normal_raw_images_patients/',('/').join(images[i].split('/')[-1].split('_')[0:2]))\n",
    "#     print(save_path_)\n",
    "    if not os.path.exists(save_path_):\n",
    "        os.makedirs(save_path_)\n",
    "    save_path = os.path.join('/data2/Cpeng/Normal_raw_images_patients/',('/').join(images[i].split('/')[-1].split('_')[0:3]))\n",
    "#     print(save_path)\n",
    "#     break\n",
    "    cv2.imwrite(save_path,image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "consolidated-worthy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45758\n"
     ]
    }
   ],
   "source": [
    "Normal_slices_raw=glob.glob('/data2/Cpeng/COVID/Normal_only_raw_images/Normal/*/*/*')\n",
    "print(len(Normal_slices_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "allied-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "class Lung_segmentation_1(Dataset):\n",
    "    def __init__(self, file_path_list, phase='train'):\n",
    "        self.path_list = file_path_list\n",
    "        self.phase = phase\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image= self.load_data(self.path_list[index])\n",
    "        image = self.process_data(image)\n",
    "        \n",
    "        return image, self.path_list[index]\n",
    "        \n",
    "    def load_data(self, file_path):\n",
    "        image = cv2.imread(file_path,0)\n",
    "        image = cv2.resize(image, (256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "        image = image-image.min()\n",
    "        image = (image/image.max()).astype(np.float32)\n",
    "        \n",
    "        return image\n",
    "        \n",
    "    def process_data(self, *args):\n",
    "        return [item[np.newaxis, :, :].astype(np.float32) for item in args]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mobile-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device('cpu' if not torch.cuda.is_available() else 'cuda')\n",
    "segmentation_model = UNet(1,1).cuda()\n",
    "checkpoint = torch.load('/data2/Cpeng/model_lung_segmentation/checkpoint_{}.pth.tar'.format(360), map_location=\"cuda:0\")\n",
    "segmentation_model.load_state_dict(checkpoint['state_dict'])\n",
    "valset = Lung_segmentation_1(file_path_list=Normal_slices_raw, phase='test')\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=40, shuffle=True, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "going-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_model.eval()\n",
    "Normal_lung_masks_dir = \"/data2/Cpeng/Normal_lung_masks/\"\n",
    "Normal_images_dir = \"/data2/Cpeng/Normal_raw_images/\"\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(val_loader):\n",
    "        image,path= data\n",
    "        image = image[0].cuda()\n",
    "#         print(path)\n",
    "        output = segmentation_model(image)\n",
    "        output = torch.sigmoid(output)\n",
    "        output[output>0.5]=1.0\n",
    "        output[output<0.5]=0.0\n",
    "        output=output.cpu().detach().numpy()\n",
    "#         output = (output*255).astype(np.uint8)\n",
    "        image=image.cpu().detach().numpy()\n",
    "        for j in range(output.shape[0]):\n",
    "            mask = output[j,0,...]\n",
    "#             image_ = image[j,0,...]\n",
    "#             plt.imshow(mask)\n",
    "#             plt.figure()\n",
    "            mask = morphology.closing(mask,morphology.square(5))\n",
    "            mask[mask>0]=1.\n",
    "            mask = mask*255\n",
    "#             plt.imshow(mask)\n",
    "            \n",
    "            image_ = image[j,0,...]\n",
    "            image_ = image_*255\n",
    "#             plt.figure()\n",
    "#             plt.imshow(image_)\n",
    "            if mask.sum()>0:\n",
    "                save_name_mask = os.path.join(Normal_lung_masks_dir,('_').join(path[j].split('/')[6:9]))\n",
    "                save_name_image = os.path.join(Normal_images_dir,('_').join(path[j].split('/')[6:9]))\n",
    "    #             print(save_name)\n",
    "#             break\n",
    "#         break\n",
    "                cv2.imwrite(save_name_mask,mask)\n",
    "                cv2.imwrite(save_name_image,image_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-ballet",
   "metadata": {},
   "source": [
    "# Re-split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "architectural-result",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825\n",
      "1043\n",
      "472\n"
     ]
    }
   ],
   "source": [
    "NCP_images_patients = glob.glob('/data2/Cpeng/NCP_raw_images_patients/*/*')\n",
    "CP_images_patients = glob.glob('/data2/Cpeng/CP_raw_images_patients/*/*')\n",
    "Normal_images_patients = glob.glob('/data2/Cpeng/Normal_raw_images_patients/*/*')\n",
    "print(len(NCP_images_patients))\n",
    "print(len(CP_images_patients))\n",
    "print(len(Normal_images_patients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sudden-narrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data2/Cpeng/NCP_raw_images_patients/222/1588\n"
     ]
    }
   ],
   "source": [
    "print(NCP_images_patients[0])\n",
    "index = '_'.join(patients_images[i].split('/')[4:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "according-default",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 660/660 [00:00<00:00, 5410.94it/s]\n",
      "100%|██████████| 165/165 [00:00<00:00, 5094.33it/s]\n",
      "100%|██████████| 834/834 [00:00<00:00, 4120.19it/s]\n",
      "100%|██████████| 209/209 [00:00<00:00, 3806.12it/s]\n",
      "100%|██████████| 377/377 [00:00<00:00, 1673.53it/s]\n",
      "100%|██████████| 95/95 [00:00<00:00, 1708.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16839\n",
      "4471\n",
      "28821\n",
      "7960\n",
      "34622\n",
      "8540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "import glob\n",
    "import os\n",
    "NCP_images_patients = glob.glob('/data2/Cpeng/NCP_raw_images_patients/*/*')\n",
    "CP_images_patients = glob.glob('/data2/Cpeng/CP_raw_images_patients/*/*')\n",
    "Normal_images_patients = glob.glob('/data2/Cpeng/Normal_raw_images_patients/*/*')\n",
    "NCP_train_patients, NCP_val_patients, _, _ = train_test_split(NCP_images_patients, NCP_images_patients, test_size=0.2, random_state=42)\n",
    "CP_train_patients, CP_val_patients, _, _ = train_test_split(CP_images_patients, CP_images_patients, test_size=0.2, random_state=42)\n",
    "Normal_train_patients, Normal_val_patients, _, _ = train_test_split(Normal_images_patients, Normal_images_patients, test_size=0.2, random_state=42)\n",
    "NCP_train = []\n",
    "NCP_val = []\n",
    "CP_train = []\n",
    "CP_val = []\n",
    "Normal_train = []\n",
    "Normal_val = []\n",
    "############### For NCP\n",
    "for i in tqdm.tqdm(range(len(NCP_train_patients))):\n",
    "    patients_images = glob.glob(NCP_train_patients[i]+'/*')\n",
    "    for j in range(len(patients_images)):\n",
    "        index = '_'.join(patients_images[j].split('/')[4:7])\n",
    "        path = os.path.join('/'.join(patients_images[j].split('/')[0:4]),index)\n",
    "        NCP_train.append(path)\n",
    "for i in tqdm.tqdm(range(len(NCP_val_patients))):\n",
    "    patients_images = glob.glob(NCP_val_patients[i]+'/*')\n",
    "    for j in range(len(patients_images)):\n",
    "        index = '_'.join(patients_images[j].split('/')[4:7])\n",
    "        path = os.path.join('/'.join(patients_images[j].split('/')[0:4]),index)\n",
    "        NCP_val.append(path)\n",
    "############### For CP\n",
    "for i in tqdm.tqdm(range(len(CP_train_patients))):\n",
    "    patients_images = glob.glob(CP_train_patients[i]+'/*')\n",
    "    for j in range(len(patients_images)):\n",
    "        index = '_'.join(patients_images[j].split('/')[4:7])\n",
    "        path = os.path.join('/'.join(patients_images[j].split('/')[0:4]),index)\n",
    "        CP_train.append(path)\n",
    "for i in tqdm.tqdm(range(len(CP_val_patients))):\n",
    "    patients_images = glob.glob(CP_val_patients[i]+'/*')\n",
    "    for j in range(len(patients_images)):\n",
    "        index = '_'.join(patients_images[j].split('/')[4:7])\n",
    "        path = os.path.join('/'.join(patients_images[j].split('/')[0:4]),index)\n",
    "        CP_val.append(path)\n",
    "############### For Normal\n",
    "for i in tqdm.tqdm(range(len(Normal_train_patients))):\n",
    "    patients_images = glob.glob(Normal_train_patients[i]+'/*')\n",
    "    for j in range(len(patients_images)):\n",
    "        index = '_'.join(patients_images[j].split('/')[4:7])\n",
    "        path = os.path.join('/'.join(patients_images[j].split('/')[0:4]),index)\n",
    "        Normal_train.append(path)\n",
    "for i in tqdm.tqdm(range(len(Normal_val_patients))):\n",
    "    patients_images = glob.glob(Normal_val_patients[i]+'/*')\n",
    "    for j in range(len(patients_images)):\n",
    "        index = '_'.join(patients_images[j].split('/')[4:7])\n",
    "        path = os.path.join('/'.join(patients_images[j].split('/')[0:4]),index)\n",
    "        Normal_val.append(path)\n",
    "print(len(NCP_train))\n",
    "print(len(NCP_val))\n",
    "print(len(CP_train))\n",
    "print(len(CP_val))\n",
    "print(len(Normal_train))\n",
    "print(len(Normal_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "moral-haiti",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data2/Cpeng/NCP_raw_images_patients/265_1677_0019.png\n"
     ]
    }
   ],
   "source": [
    "print(NCP_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-survey",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
